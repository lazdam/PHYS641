{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b8a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76452ec4",
   "metadata": {},
   "source": [
    "# Problem #1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9767a6de",
   "metadata": {},
   "source": [
    "See attached PDF. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912e021",
   "metadata": {},
   "source": [
    "# Problem #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82fd61c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by defining our two PDFs. Note that I have converted the poisson into log poisson and taken \n",
    "# the exponential of it to get the probability. I've also used Stirling's approximation to remove \n",
    "# the factorial. \n",
    "\n",
    "def gauss(lamda, a = 3):\n",
    "    x = lamda + a*np.sqrt(lamda)\n",
    "    return 1/np.sqrt(2*np.pi*lamda) * np.exp(-(x - lamda)**2 / (2*lamda))\n",
    "\n",
    "\n",
    "def log_poisson(lamda, a = 3):\n",
    "    x = lamda + a*np.sqrt(lamda)\n",
    "    return np.exp(-0.5*np.log(2*np.pi*x) + x*np.log(lamda/x) - lamda + x)\n",
    "\n",
    "\n",
    "def _get_minimum_lambda(a):\n",
    "    \"\"\"Calculate the minimum value of lambda such that 1 < P/G < 2 is true at n = λ + a\\sqrt(λ). \n",
    "    \n",
    "    Parameters: \n",
    "    -----------\n",
    "    a: int\n",
    "        Coefficient corresponding to sigma level you wish to compare the poisson and gaussian distributions, e.g.\n",
    "        5 sigma level ==> a = 5. \n",
    "        \n",
    "    Returns:\n",
    "    lambda: int\n",
    "        Minimum lambda. \n",
    "    n: int\n",
    "        Minimum number of repetitions. \n",
    "    \"\"\"\n",
    "\n",
    "    lamda = 1 \n",
    "    _gauss = gauss(lamda, a = a)\n",
    "    _poisson = log_poisson(lamda, a = a)\n",
    "    \n",
    "    ratio = _poisson/_gauss\n",
    "    \n",
    "    while ratio > 2 or ratio < 1: \n",
    "        lamda+=1 \n",
    "        _gauss = gauss(lamda, a = a)\n",
    "        _poisson = log_poisson(lamda, a = a)\n",
    "        ratio = _poisson/_gauss\n",
    "    \n",
    "    n = lamda + a*np.sqrt(lamda)\n",
    "    \n",
    "    return lamda, int(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd2954",
   "metadata": {},
   "source": [
    "### Sigma level: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "056ac385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Poisson and Gaussian to agree at the 3σ level, we would need λ = 9 corresponding to a minimum number of repetitions of n = 18. \n"
     ]
    }
   ],
   "source": [
    "sig_level = 3\n",
    "lamda, n = _get_minimum_lambda(sig_level)\n",
    "print('For Poisson and Gaussian to agree at the 3σ level, we would need λ = {0} corresponding to a minimum number of repetitions of n = {1}. '.format(lamda, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f31492",
   "metadata": {},
   "source": [
    "### Sigma level: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f112fc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Poisson and Gaussian to agree at the 5σ level, we would need λ = 576 corresponding to a minimum number of repetitions of n = 696. \n"
     ]
    }
   ],
   "source": [
    "sig_level = 5\n",
    "lamda, n = _get_minimum_lambda(sig_level)\n",
    "print('For Poisson and Gaussian to agree at the 5σ level, we would need λ = {0} corresponding to a minimum number of repetitions of n = {1}. '.format(lamda, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe366ba",
   "metadata": {},
   "source": [
    "# Problem #3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6089ab2",
   "metadata": {},
   "source": [
    "See attached PDF. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b416fc5",
   "metadata": {},
   "source": [
    "# Problem #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "571696b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5,5,51)\n",
    "npts = len(x)\n",
    "tot_chunks = 10000\n",
    "\n",
    "# Generate 10000 samples, each defined by a gaussian with random noise added to it.\n",
    "signal_arr = np.exp(-x[:,np.newaxis]**2/2) + np.random.randn(npts, tot_chunks)\n",
    "\n",
    "# Get noise by taking variance of each chunk\n",
    "noise = np.var(signal_arr, axis = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f1b0a4",
   "metadata": {},
   "source": [
    "The model parameter that we are interested in fitting for is the amplitude of the Gaussian, e.g. \n",
    "\\begin{equation}\n",
    "f(x) = m \\cdot \\text{exp}\\left[\\frac{-x^2}{2}\\right],\n",
    "\\end{equation}\n",
    "where $m$ is the amplitude that we expect $\\langle m \\rangle = m_{\\text{true}} = 1$. To do this, we recall that the least-squares best fit parameter can be obtained using the equation:\n",
    "\\begin{equation}\n",
    "m = (A^TN^{-1}A)^{-1}A^TN^{-1}d, \n",
    "\\end{equation}\n",
    "with the error on the estimate being\n",
    "\\begin{equation}\n",
    "\\delta m = (A^TN^{-1}A)^{-1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da004e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_gauss(x):\n",
    "    return np.exp(-x**2 / 2)\n",
    "\n",
    "\n",
    "# Build our A matrix using our model. Will be a (51,) array\n",
    "A = unit_gauss(x)\n",
    "\n",
    "# Iterate over all the chunks\n",
    "m_arr = []\n",
    "m_err_arr = []\n",
    "for i in range(tot_chunks):\n",
    "    \n",
    "    # Noise is uncorrelated, so matrix will be diagonal, square, with dimensions npts x npts\n",
    "    _Ninv = 1/noise[i] * np.eye(npts)  \n",
    "    _lhs = A[:, np.newaxis].T@_Ninv@A\n",
    "    _rhs = A[:,np.newaxis].T@_Ninv@signal_arr[:,i]\n",
    "    \n",
    "    # Save inverse of lhs for error on best fit param. Since it's 1-D, it's simply 1 / lhs. \n",
    "    _lhs_inv = 1 / _lhs \n",
    "    \n",
    "    # Compute best fit parameters\n",
    "    _m = _lhs_inv@_rhs\n",
    "    \n",
    "    m_arr.append(_m)\n",
    "    m_err_arr.append(np.sqrt(_lhs_inv[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9175ce88",
   "metadata": {},
   "source": [
    "To show that on average,  $\\langle m \\rangle = m_{\\text{true}}$, we simply average over all 10000 samples and look at the average value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8aca23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value of fit amplitude over 10000 samples is:  < m > = 0.9982162413239939 ± 0.3494662512679676\n"
     ]
    }
   ],
   "source": [
    "print('Average value of fit amplitude over {0} samples is:  < m > = {1} ± {2}'.format(tot_chunks, np.mean(m_arr), np.mean(m_err_arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a3f9a5",
   "metadata": {},
   "source": [
    "The expected value of $m_{\\text{true}} = 1$ falls within our average value with averaged 1$\\sigma$ error bars. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7072d",
   "metadata": {},
   "source": [
    "### Weighted Average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe48e6b1",
   "metadata": {},
   "source": [
    "To get the weighted average, we simply use the following formula: \n",
    "\\begin{equation}\n",
    "m = \\frac{\\sum_iw_im_i}{\\sum_iw_i}.\n",
    "\\end{equation}\n",
    "with variance (from question 2)\n",
    "\\begin{equation}\n",
    "\\text{Var}[m] = \\frac{\\sum_i w_i^2\\text{Var}[m_i]}{\\sum_iw_i^2} = \\frac{\\sum_i w_i^2\\sigma_i^2}{\\sum_iw_i^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3103fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (1/np.asarray(m_err_arr))**2\n",
    "m_weighted = np.sum(np.asarray(m_arr)*weights)/np.sum(weights)\n",
    "m_weighted_var = np.sum((weights*np.asarray(m_err_arr))**2)/np.sum(weights)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d458420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the weighted mean, we find m = 0.9752139927205926  ± 0.0034432312094356487\n"
     ]
    }
   ],
   "source": [
    "print('Using the weighted mean, we find m = {0}  ± {1}'.format(m_weighted, np.sqrt(m_weighted_var)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8b095d",
   "metadata": {},
   "source": [
    "As we can see, it has clearly biased our amplitude low by roughly 3%. As to why? We are using our model to estimate the noise statistics, so if we wanted to avoid this bias, we would want to estimate the noise statistics using the underlying physics that is causing the noise (and not taking the variance of the signal). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a52a300",
   "metadata": {},
   "source": [
    "# Problem #5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc32fb",
   "metadata": {},
   "source": [
    "See attached PDF. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chime_env",
   "language": "python",
   "name": "chime_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
